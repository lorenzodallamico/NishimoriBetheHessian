{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "\n",
    "In this notebook we provide a demo on how to use our proposed algorithm for node classification in weighted graphs. We will also provide the elementary tools to recreate the outcomes of Figures 6, 7, 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the source files\n",
    "\n",
    "include(\"src/basic_functions.jl\")\n",
    "include(\"src/NBNC.jl\")\n",
    "include(\"src/clustering_algorithms.jl\")\n",
    "\n",
    "using Plots, LaTeXStrings ## these packages are used just for the plots\n",
    "using DelimitedFiles ## this is to upload the GAN features\n",
    "\n",
    "\n",
    "\n",
    "gr(size=(140,100), xtickfontsize = 4, ytickfontsize = 4, linewidth = 0.5, legendfontsize = 2, markersize = 2)\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering on synthetic data\n",
    "\n",
    "With the following code we show the performance of label inference on synthetic data, according to the following steps:\n",
    "\n",
    "* Generate the graph $\\mathcal{G}(\\mathcal{V},\\mathcal{E})$. One can simply generate a Erdos-Renyi graph or its degree-corrected version, to obtain an arbitrary degree distribution.\n",
    "* Assign the weights to each edge. The weights are assigned keeping under consideration the class labels that have to be estimated. We here propose two weights assignments: the Gaussian weight and the binary weight.\n",
    "* Run the algorithms based on the ``Nishimori Bethe-Hessian``, the ``spin-glass Bethe-Hessian``, the ``na\\\"ive mean field`` method and finally the ``weighted Laplacian`` matrix. All algorithms output the estimated labels and the vector ``X`` from which the labels have been estimated.\n",
    "* We finally show the performance of reconstruction in terms of overlap for all the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mo The value of β_SG is 0.17. Computing β_N\u001b[39m\n",
      "\n",
      "\u001b[38;5;4mIteration # 1: \u001b[39m\n",
      "\u001b[38;5;4mThe current estimate of β_N is 0.2383169502138014\u001b[39m\n",
      "\u001b[38;5;4mThe smallest eigenvalue is -0.16378928067361181\u001b[39m\n",
      "\n",
      "\u001b[38;5;4mIteration # 2: \u001b[39m\n",
      "\u001b[38;5;4mThe current estimate of β_N is 0.2489633329220985\u001b[39m\n",
      "\u001b[38;5;4mThe smallest eigenvalue is -0.04060721587161855\u001b[39m\n",
      "\n",
      "\u001b[38;5;4mIteration # 3: \u001b[39m\n",
      "\u001b[38;5;4mThe current estimate of β_N is 0.24918818696887746\u001b[39m\n",
      "\u001b[38;5;4mThe smallest eigenvalue is -0.0008493867954859237\u001b[39m\n",
      "\n",
      "\u001b[38;5;4mIteration # 4: \u001b[39m\n",
      "\u001b[38;5;4mThe current estimate of β_N is 0.24918818696887746\u001b[39m\n",
      "\u001b[38;5;4mThe smallest eigenvalue is -3.873945201697472e-7\u001b[39m\n",
      "\n",
      "\u001b[38;5;2mo The value of β_N is 0.25\u001b[39m\n",
      "\u001b[38;5;2mo Running kmeans\u001b[39m\n",
      "\u001b[38;5;2mo Done!\u001b[39m\n",
      "\u001b[38;5;2mo Running kmeans\u001b[39m\n",
      "\u001b[38;5;2mo Done!\u001b[39m\n",
      "\u001b[38;5;2mo Running kmeans\u001b[39m\n",
      "\u001b[38;5;2mo Done!\u001b[39m\n",
      "\u001b[38;5;2mo The value of β_SG is 0.17\u001b[39m\n",
      "\u001b[38;5;2mo Running kmeans\u001b[39m\n",
      "\u001b[38;5;2mo Done!\u001b[39m\n",
      "  0.626797 seconds (174.49 k allocations: 774.657 MiB, 3.06% gc time)\n",
      "\n",
      "The overlaps obtained are:\n",
      "\n",
      " BH Nishimori = 0.6106666666666667\n",
      " BH spin glass = 0.5920000000000001\n",
      " Mean field = 0.002666666666666706\n",
      " Laplacian = 0.0013333333333334085"
     ]
    }
   ],
   "source": [
    "@time begin\n",
    "\n",
    "n = 3000 # number of nodes\n",
    "c = 8. # average degree\n",
    "    \n",
    "ℓ = ones(n) # label vector\n",
    "ℓ[1:Int(n/2)] .= -1\n",
    "\n",
    "\"\"\" Now we build the adjacency matrix. If, instead of using a Erdos Renyi graph, one wants to create a heterogeneous\n",
    "    degree distribution like in the one used in Figure 7, instead of using the function ```adjacency_matrix_ER```, \n",
    "    use the function ```adjacency_matrix_DCER``` (commented below). Note that the implementation of the function\n",
    "    ```adjacency_matrix_DCER``` is adapted only to sparse graphs.\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "A, edge_list = adjacency_matrix_ER(c,n) # generate the adjacency matrix of the Erdos-Renyi graph\n",
    "    \n",
    "# To obtain an arbitrary degree distribution uncomment the following lines of code\n",
    "    \n",
    "# θ = rand(Uniform(3,10),n).^4 # this vector θ generates a power law degree distribution\n",
    "# θ = θ/mean(θ)\n",
    "# A, edge_list =  adjacency_matrix_DCER(c,θ)\n",
    "\n",
    "    \n",
    "\"\"\" Now we initialize the parameters for the simulation \"\"\"\n",
    "    \n",
    "μ = 1. # mean of the Gaussian\n",
    "ν = 2. # standard deviation of the Gaussian\n",
    "p = 0.7\n",
    "\n",
    "verbose = 2\n",
    "    \n",
    "\n",
    "J_edge_list = zeros(length(edge_list[:,1])) # assign the weights to each edge according to Equation 27\n",
    "\n",
    "    \n",
    "\"\"\" With this bit of code we get a weighted graph. In this case β_N = μ/ν^2 \"\"\"\n",
    "    \n",
    "for k=1:length(J_edge_list)\n",
    "    a = edge_list[k,1]\n",
    "    b = edge_list[k,2]\n",
    "    J_edge_list[k] = rand(Normal(μ*ℓ[a]*ℓ[b],ν))\n",
    "end\n",
    "    \n",
    "\"\"\" With this bit of code we obtain a signed graph. In this case β_N = atanh(2p-1) \"\"\"\n",
    "\n",
    "# for k=1:length(J_edge_list)\n",
    "#     a = edge_list[k,1]\n",
    "#     b = edge_list[k,2]\n",
    "#     rn = rand(Uniform(0,1))\n",
    "#     if rn < p\n",
    "#         J_edge_list[k] = ℓ[a]*ℓ[b]\n",
    "#      else\n",
    "#         J_edge_list[k] = -ℓ[a]*ℓ[b]\n",
    "#     end\n",
    "# end\n",
    "    \n",
    "    \n",
    "    \n",
    "# Run the four clustering algorithms discussed in the article\n",
    "\n",
    "X, estimated_ℓ = clustering_BH_Nishimori(edge_list, J_edge_list, n, verbose = verbose)\n",
    "X_LAP, estimated_ℓ_LAP = clustering_signed_Lap(edge_list, J_edge_list, n, verbose = verbose)\n",
    "X_MF, estimated_ℓ_MF = clustering_MF(edge_list, J_edge_list, n, verbose = verbose)\n",
    "X_SG, estimated_ℓ_SG = clustering_BH_SG(edge_list, J_edge_list, n)\n",
    "\n",
    "Overlap = abs(2*(sum(estimated_ℓ .== ℓ)/n - 0.5))\n",
    "OverlapLAP = abs(2*(sum(estimated_ℓ_LAP .== ℓ)/n - 0.5))\n",
    "OverlapMF = abs(2*(sum(estimated_ℓ_MF .== ℓ)/n - 0.5))\n",
    "OverlapSG = abs(2*(sum(estimated_ℓ_SG .== ℓ)/n - 0.5))\n",
    "\n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "print(\"\\nThe overlaps obtained are:\\n\",\n",
    " \"\\n BH Nishimori = \", Overlap,\n",
    "\"\\n BH spin glass = \", OverlapSG,\n",
    "\"\\n Mean field = \", OverlapMF,\n",
    "\"\\n Laplacian = \", OverlapLAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering on real data\n",
    "\n",
    "Here we show how to implement our algorithm for data clustering. The steps are the following:\n",
    "\n",
    "* Upload the raw data: the matrix $Y \\in \\mathbb{R}^{n \\times p}$ contains the data of the features extracted from the GAN images. We attached to files: ``features.dat``, used to produce Figure 8 with 40k images and ``features_small.dat`` with 6k images for a faster implementation. In both datasets, the first half of the images belong to one class and the second half to the other.\n",
    "* The mask $S$ is applied to the signal, obtaining the input matrix $X$.\n",
    "* We then build the weighted graph, first building a Erdos-Renyi, then assigning to each edge $(ij)$ the weight $\\frac{1}{p}x_i^Tx_j$\n",
    "* We then shift the average of the weights to zero\n",
    "* Finally we run the different algorithms and compare the performance in terms of overlap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = readdlm(\"data/features.dat\") ## upload the data\n",
    "\n",
    "# Y = readdlm(\"data/features_small.dat\") ## upload the data\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mo The value of β_SG is 0.31. Computing β_N\u001b[39m\n",
      "\n",
      "\u001b[38;5;166mThe signed representation of J is adopted. If you want to use the weighted one, increase the value of `is_signed_th`. The algorithm might have a sensible slow down\u001b[39m\n",
      "\n",
      "\u001b[38;5;4mIteration # 1: \u001b[39m\n",
      "\u001b[38;5;4mThe current estimate of β_N is 1.250011606354928\u001b[39m\n",
      "\u001b[38;5;4mThe smallest eigenvalue is -11.942699185708316\u001b[39m\n",
      "\n",
      "\u001b[38;5;4mIteration # 2: \u001b[39m\n",
      "\u001b[38;5;4mThe current estimate of β_N is 1.4288754042783092\u001b[39m\n",
      "\u001b[38;5;4mThe smallest eigenvalue is -0.4002598380955845\u001b[39m\n",
      "\n",
      "\u001b[38;5;4mIteration # 3: \u001b[39m\n",
      "\u001b[38;5;4mThe current estimate of β_N is 1.430612779368753\u001b[39m\n",
      "\u001b[38;5;4mThe smallest eigenvalue is -0.003117815806615139\u001b[39m\n",
      "\n",
      "\u001b[38;5;4mIteration # 4: \u001b[39m\n",
      "\u001b[38;5;4mThe current estimate of β_N is 1.430612779368753\u001b[39m\n",
      "\u001b[38;5;4mThe smallest eigenvalue is -2.2613805496545056e-7\u001b[39m\n",
      "\n",
      "\u001b[38;5;2mo The value of β_N is 1.43\u001b[39m\n",
      "\u001b[38;5;2mo Running kmeans\u001b[39m\n",
      "\u001b[38;5;2mo Done!\u001b[39m\n",
      "\u001b[38;5;2mo Running kmeans\u001b[39m\n",
      "\u001b[38;5;2mo Done!\u001b[39m\n",
      "\u001b[38;5;2mo Running kmeans\u001b[39m\n",
      "\u001b[38;5;2mo Done!\u001b[39m\n",
      "\u001b[38;5;2mo The value of β_SG is 0.31\u001b[39m\n",
      "\u001b[38;5;2mo Running kmeans\u001b[39m\n",
      "\u001b[38;5;2mo Done!\u001b[39m\n",
      "  7.389867 seconds (3.39 M allocations: 2.990 GiB, 1.09% gc time)\n",
      "\n",
      "The overlaps obtained are:\n",
      "\n",
      " BH Nishimori = 0.9728000000000001\n",
      " BH spin glass = 0.97125\n",
      " Mean field = 0.9702500000000001\n",
      " Laplacian = 5.0000000000105516e-5"
     ]
    }
   ],
   "source": [
    "@time begin\n",
    "    \n",
    "n = length(Y[:,1]) # number of nodes\n",
    "p = length(Y[1,:]) # number of features\n",
    "    \n",
    "\n",
    "c = 10. # average degree\n",
    "ϵ = 2*10^(-5) # precision error\n",
    "verbose = 2\n",
    "       \n",
    "    \n",
    "κ = sqrt(p/p)\n",
    "S = rand(Binomial(1,κ), (n,p))\n",
    "X = Y.*S # apply the mask to the signal\n",
    "\n",
    "ℓ = ones(n)\n",
    "ℓ[1:Int(n/2)] .= -1\n",
    "        \n",
    "A, edge_list = adjacency_matrix_ER(c,n) # generate the adjacency matrix of the Erdos-Renyi graph\n",
    "\n",
    "J_edge_list = zeros(length(edge_list[:,1]))\n",
    "\n",
    "for k=1:length(J_edge_list)\n",
    "    a = edge_list[k,1]\n",
    "    b = edge_list[k,2]\n",
    "    J_edge_list[k] = X[a,:]'*X[b,:]/p # covariance matrix\n",
    "end\n",
    "\n",
    "J_edge_list = J_edge_list .- mean(J_edge_list) # shifht the non-zero entries\n",
    "# J_edge_list = sign.(J_edge_list) # take a signed representation of the graph\n",
    "\n",
    "# Run the four clustering algorithms discussed in the article\n",
    "\n",
    "X, estimated_ℓ = clustering_BH_Nishimori(edge_list, J_edge_list, n, verbose = verbose)\n",
    "X_LAP, estimated_ℓ_LAP = clustering_signed_Lap(edge_list, J_edge_list, n, verbose = verbose)\n",
    "X_MF, estimated_ℓ_MF = clustering_MF(edge_list, J_edge_list, n, verbose = verbose)\n",
    "X_SG, estimated_ℓ_SG = clustering_BH_SG(edge_list, J_edge_list, n)\n",
    "\n",
    "Overlap = abs(2*(sum(estimated_ℓ .== ℓ)/n - 0.5))\n",
    "OverlapLAP = abs(2*(sum(estimated_ℓ_LAP .== ℓ)/n - 0.5))\n",
    "OverlapMF = abs(2*(sum(estimated_ℓ_MF .== ℓ)/n - 0.5))\n",
    "OverlapSG = abs(2*(sum(estimated_ℓ_SG .== ℓ)/n - 0.5))\n",
    "\n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "print(\"\\nThe overlaps obtained are:\\n\",\n",
    " \"\\n BH Nishimori = \", Overlap,\n",
    "\"\\n BH spin glass = \", OverlapSG,\n",
    "\"\\n Mean field = \", OverlapMF,\n",
    "\"\\n Laplacian = \", OverlapLAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
