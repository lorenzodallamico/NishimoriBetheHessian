{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "\n",
    "In this notebook we provide a demo on how to use our proposed algorithm for node classification in weighted graphs. We will also provide the elementary tools to recreate the outcomes of Figures 6, 7, 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the source files\n",
    "\n",
    "include(\"src/basic_functions.jl\")\n",
    "include(\"src/NBNC.jl\")\n",
    "include(\"src/clustering_algorithms.jl\")\n",
    "\n",
    "using Plots, LaTeXStrings ## these packages are used just for the plots\n",
    "using DelimitedFiles ## this is to upload the GAN features\n",
    "\n",
    "\n",
    "\n",
    "gr(size=(140,100), xtickfontsize = 4, ytickfontsize = 4, linewidth = 0.5, legendfontsize = 2, markersize = 2)\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering on synthetic data\n",
    "\n",
    "With the following code we show the performance of label inference on synthetic data, according to the following steps:\n",
    "\n",
    "* Generate the graph $\\mathcal{G}(\\mathcal{V},\\mathcal{E})$. One can simply generate a Erdos-Renyi graph or its degree-corrected version, to obtain an arbitrary degree distribution.\n",
    "* Assign the weights to each edge. The weights are assigned keeping under consideration the class labels that have to be estimated. We here propose two weights assignments: the Gaussian weight and the binary weight.\n",
    "* Run the algorithms based on the ``Nishimori Bethe-Hessian``, the ``spin-glass Bethe-Hessian``, the ``na\\\"ive mean field`` method and finally the ``weighted Laplacian`` matrix. All algorithms output the estimated labels and the vector ``X`` from which the labels have been estimated.\n",
    "* We finally show the performance of reconstruction in terms of overlap for all the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mo The value of β_SG is 0.43. Computing β_N\u001b[39m\n",
      "\n",
      "\u001b[38;5;166mThe signed representation of J is adopted. If you want to use the weighted one, increase the value of `is_signed_th`. The algorithm might have a sensible slow down\u001b[39m\n",
      "\n",
      "\u001b[38;5;4mIteration # 1: \u001b[39m\n",
      "\u001b[38;5;4mThe current estimate of β_N is 0.7937306738909091\u001b[39m\n",
      "\u001b[38;5;4mThe smallest eigenvalue is -0.9659398063026835\u001b[39m\n",
      "\n",
      "\u001b[38;5;4mIteration # 2: \u001b[39m\n",
      "\u001b[38;5;4mThe current estimate of β_N is 0.8672111750608897\u001b[39m\n",
      "\u001b[38;5;4mThe smallest eigenvalue is -0.14032339819045755\u001b[39m\n",
      "\n",
      "\u001b[38;5;4mIteration # 3: \u001b[39m\n",
      "\u001b[38;5;4mThe current estimate of β_N is 0.869518374496644\u001b[39m\n",
      "\u001b[38;5;4mThe smallest eigenvalue is -0.0039183466103313806\u001b[39m\n",
      "\n",
      "\u001b[38;5;4mIteration # 4: \u001b[39m\n",
      "\u001b[38;5;4mThe current estimate of β_N is 0.869518374496644\u001b[39m\n",
      "\u001b[38;5;4mThe smallest eigenvalue is -3.694419990720239e-6\u001b[39m\n",
      "\n",
      "\u001b[38;5;2mo The value of β_N is 0.87\u001b[39m\n",
      "\u001b[38;5;2mo Running kmeans\u001b[39m\n",
      "\u001b[38;5;2mo Done!\u001b[39m\n",
      "\u001b[38;5;2mo Running kmeans\u001b[39m\n",
      "\u001b[38;5;2mo Done!\u001b[39m\n",
      "\u001b[38;5;2mo Running kmeans\u001b[39m\n",
      "\u001b[38;5;2mo Done!\u001b[39m\n",
      "\u001b[38;5;2mo The value of β_SG is 0.43\u001b[39m\n",
      "\u001b[38;5;2mo Running kmeans\u001b[39m\n",
      "\u001b[38;5;2mo Done!\u001b[39m\n",
      "  3.223318 seconds (934.48 k allocations: 805.917 MiB, 1.04% gc time)\n",
      "\n",
      "The overlaps obtained are:\n",
      "\n",
      " BH Nishimori = 0.8374666666666666\n",
      " BH spin glass = 0.8242\n",
      " Mean field = 0.7716000000000001\n",
      " Laplacian = 0.0013333333333334085"
     ]
    }
   ],
   "source": [
    "@time begin\n",
    "\n",
    "n = 30000 # number of nodes\n",
    "c = 5. # average degree\n",
    "    \n",
    "ℓ = ones(n) # label vector\n",
    "ℓ[1:Int(n/2)] .= -1\n",
    "\n",
    "\"\"\" Now we build the adjacency matrix. If, instead of using a Erdos Renyi graph, one wants to create a heterogeneous\n",
    "    degree distribution like in the one used in Figure 7, instead of using the function ```adjacency_matrix_ER```, \n",
    "    use the function ```adjacency_matrix_DCER``` (commented below). Note that the implementation of the function\n",
    "    ```adjacency_matrix_DCER``` is adapted only to sparse graphs.\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "A, edge_list = adjacency_matrix_ER(c,n) # generate the adjacency matrix of the Erdos-Renyi graph\n",
    "    \n",
    "# To obtain an arbitrary degree distribution uncomment the following lines of code\n",
    "    \n",
    "# θ = rand(Uniform(3,10),n).^4 # this vector θ generates a power law degree distribution\n",
    "# θ = θ/mean(θ)\n",
    "# A, edge_list =  adjacency_matrix_DCER(c,θ)\n",
    "\n",
    "    \n",
    "\"\"\" Now we initialize the parameters for the simulation \"\"\"\n",
    "    \n",
    "μ = 1. # mean of the Gaussian\n",
    "ν = 1. # standard deviation of the Gaussian\n",
    "p = 0.85\n",
    "\n",
    "verbose = 2\n",
    "    \n",
    "\n",
    "J_edge_list = zeros(length(edge_list[:,1])) # assign the weights to each edge according to Equation 27\n",
    "\n",
    "    \n",
    "\"\"\" With this bit of code we get a weighted graph. In this case β_N = μ/ν^2 \"\"\"\n",
    "    \n",
    "# for k=1:length(J_edge_list)\n",
    "#     a = edge_list[k,1]\n",
    "#     b = edge_list[k,2]\n",
    "#     J_edge_list[k] = rand(Normal(μ*ℓ[a]*ℓ[b],ν))\n",
    "# end\n",
    "    \n",
    "\"\"\" With this bit of code we obtain a signed graph. In this case β_N = atanh(2p-1) \"\"\"\n",
    "\n",
    "for k=1:length(J_edge_list)\n",
    "    a = edge_list[k,1]\n",
    "    b = edge_list[k,2]\n",
    "    rn = rand(Uniform(0,1))\n",
    "    if rn < p\n",
    "        J_edge_list[k] = ℓ[a]*ℓ[b]\n",
    "     else\n",
    "        J_edge_list[k] = -ℓ[a]*ℓ[b]\n",
    "    end\n",
    "end\n",
    "    \n",
    "    \n",
    "    \n",
    "# Run the four clustering algorithms discussed in the article\n",
    "\n",
    "X, estimated_ℓ = clustering_BH_Nishimori(edge_list, J_edge_list, n, verbose = verbose)\n",
    "X_LAP, estimated_ℓ_LAP = clustering_signed_Lap(edge_list, J_edge_list, n, verbose = verbose)\n",
    "X_MF, estimated_ℓ_MF = clustering_MF(edge_list, J_edge_list, n, verbose = verbose)\n",
    "X_SG, estimated_ℓ_SG = clustering_BH_SG(edge_list, J_edge_list, n)\n",
    "\n",
    "Overlap = abs(2*(sum(estimated_ℓ .== ℓ)/n - 0.5))\n",
    "OverlapLAP = abs(2*(sum(estimated_ℓ_LAP .== ℓ)/n - 0.5))\n",
    "OverlapMF = abs(2*(sum(estimated_ℓ_MF .== ℓ)/n - 0.5))\n",
    "OverlapSG = abs(2*(sum(estimated_ℓ_SG .== ℓ)/n - 0.5))\n",
    "\n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "print(\"\\nThe overlaps obtained are:\\n\",\n",
    " \"\\n BH Nishimori = \", Overlap,\n",
    "\"\\n BH spin glass = \", OverlapSG,\n",
    "\"\\n Mean field = \", OverlapMF,\n",
    "\"\\n Laplacian = \", OverlapLAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering on real data\n",
    "\n",
    "Here we show how to implement our algorithm for data clustering. The steps are the following:\n",
    "\n",
    "* Upload the raw data: the matrix $Y \\in \\mathbb{R}^{n \\times p}$ contains the data of the features extracted from the GAN images. We attached to files: ``featuresGAN.dat``, used to produce Figure 8 with 40k images and ``featuresGAN_small.dat`` with 6k images for a faster implementation. In both datasets, the first half of the images belong to one class and the second half to the other.\n",
    "* The mask $S$ is applied to the signal, obtaining the input matrix $X$.\n",
    "* We then build the weighted graph, first building a Erdos-Renyi, then assigning to each edge $(ij)$ the weight $\\frac{1}{p}x_i^Tx_j$\n",
    "* We then shift the average of the weights to zero\n",
    "* Finally we run the different algorithms and compare the performance in terms of overlap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y = readdlm(\"data/featuresGAN.dat\") ## upload the data\n",
    "\n",
    "Y = readdlm(\"data/featuresGAN_small.dat\") ## upload the data\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mo The value of β_SG is 17.59. Computing β_N\u001b[39m\n",
      "\n",
      "\u001b[38;5;4mIteration # 1: \u001b[39m\n",
      "\u001b[38;5;4mThe current estimate of β_N is 27.743484630308636\u001b[39m\n",
      "\u001b[38;5;4mThe smallest eigenvalue is -1.028744651017409\u001b[39m\n",
      "\n",
      "\u001b[38;5;4mIteration # 2: \u001b[39m\n",
      "\u001b[38;5;4mThe current estimate of β_N is 31.02946553641683\u001b[39m\n",
      "\u001b[38;5;4mThe smallest eigenvalue is -0.4210301222484582\u001b[39m\n",
      "\n",
      "\u001b[38;5;4mIteration # 3: \u001b[39m\n",
      "\u001b[38;5;4mThe current estimate of β_N is 32.2364391893\u001b[39m\n",
      "\u001b[38;5;4mThe smallest eigenvalue is -0.1122177536637786\u001b[39m\n",
      "\n",
      "\u001b[38;5;4mIteration # 4: \u001b[39m\n",
      "\u001b[38;5;4mThe current estimate of β_N is 32.61461531898749\u001b[39m\n",
      "\u001b[38;5;4mThe smallest eigenvalue is -0.02336298743936211\u001b[39m\n",
      "\n",
      "\u001b[38;5;4mIteration # 5: \u001b[39m\n",
      "\u001b[38;5;4mThe current estimate of β_N is 32.703973235232304\u001b[39m\n",
      "\u001b[38;5;4mThe smallest eigenvalue is -0.003817137976602075\u001b[39m\n",
      "\n",
      "\u001b[38;5;4mIteration # 6: \u001b[39m\n",
      "\u001b[38;5;4mThe current estimate of β_N is 32.71162376893814\u001b[39m\n",
      "\u001b[38;5;4mThe smallest eigenvalue is -0.00028119146563640294\u001b[39m\n",
      "\n",
      "\u001b[38;5;4mIteration # 7: \u001b[39m\n",
      "\u001b[38;5;4mThe current estimate of β_N is 32.71162376893814\u001b[39m\n",
      "\u001b[38;5;4mThe smallest eigenvalue is -2.151535825382775e-6\u001b[39m\n",
      "\n",
      "\u001b[38;5;2mo The value of β_N is 32.71\u001b[39m\n",
      "\u001b[38;5;2mo Running kmeans\u001b[39m\n",
      "\u001b[38;5;2mo Done!\u001b[39m\n",
      "\u001b[38;5;2mo Running kmeans\u001b[39m\n",
      "\u001b[38;5;2mo Done!\u001b[39m\n",
      "\u001b[38;5;2mo Running kmeans\u001b[39m\n",
      "\u001b[38;5;2mo Done!\u001b[39m\n",
      "\u001b[38;5;2mo The value of β_SG is 17.59\u001b[39m\n",
      "\u001b[38;5;2mo Running kmeans\u001b[39m\n",
      "\u001b[38;5;2mo Done!\u001b[39m\n",
      "  4.531887 seconds (643.29 k allocations: 4.274 GiB, 5.79% gc time)\n",
      "\n",
      "The overlaps obtained are:\n",
      "\n",
      " BH Nishimori = 0.7453333333333334\n",
      " BH spin glass = 0.7296666666666667\n",
      " Mean field = 0.002666666666666595\n",
      " Laplacian = 0.0003333333333332966"
     ]
    }
   ],
   "source": [
    "@time begin\n",
    "    \n",
    "n = length(Y[:,1]) # number of nodes\n",
    "p = length(Y[1,:]) # number of features\n",
    "    \n",
    "\n",
    "c = 10. # average degree\n",
    "ϵ = 2*10^(-5) # precision error\n",
    "verbose = 2\n",
    "       \n",
    "    \n",
    "κ = sqrt(20/p)\n",
    "S = rand(Binomial(1,κ), (n,p))\n",
    "X = Y.*S # apply the mask to the signal\n",
    "\n",
    "ℓ = ones(n)\n",
    "ℓ[1:Int(n/2)] .= -1\n",
    "        \n",
    "A, edge_list = adjacency_matrix_ER(c,n) # generate the adjacency matrix of the Erdos-Renyi graph\n",
    "\n",
    "J_edge_list = zeros(length(edge_list[:,1]))\n",
    "\n",
    "for k=1:length(J_edge_list)\n",
    "    a = edge_list[k,1]\n",
    "    b = edge_list[k,2]\n",
    "    J_edge_list[k] = X[a,:]'*X[b,:]/p # covariance matrix\n",
    "end\n",
    "\n",
    "J_edge_list = J_edge_list .- mean(J_edge_list) # shifht the non-zero entries\n",
    "# J_edge_list = sign.(J_edge_list)\n",
    "\n",
    "# Run the four clustering algorithms discussed in the article\n",
    "\n",
    "X, estimated_ℓ = clustering_BH_Nishimori(edge_list, J_edge_list, n, verbose = verbose)\n",
    "X_LAP, estimated_ℓ_LAP = clustering_signed_Lap(edge_list, J_edge_list, n, verbose = verbose)\n",
    "X_MF, estimated_ℓ_MF = clustering_MF(edge_list, J_edge_list, n, verbose = verbose)\n",
    "X_SG, estimated_ℓ_SG = clustering_BH_SG(edge_list, J_edge_list, n)\n",
    "\n",
    "Overlap = abs(2*(sum(estimated_ℓ .== ℓ)/n - 0.5))\n",
    "OverlapLAP = abs(2*(sum(estimated_ℓ_LAP .== ℓ)/n - 0.5))\n",
    "OverlapMF = abs(2*(sum(estimated_ℓ_MF .== ℓ)/n - 0.5))\n",
    "OverlapSG = abs(2*(sum(estimated_ℓ_SG .== ℓ)/n - 0.5))\n",
    "\n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "print(\"\\nThe overlaps obtained are:\\n\",\n",
    " \"\\n BH Nishimori = \", Overlap,\n",
    "\"\\n BH spin glass = \", OverlapSG,\n",
    "\"\\n Mean field = \", OverlapMF,\n",
    "\"\\n Laplacian = \", OverlapLAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
